/**
 * @file npie_internal.h
 * @brief NPIE Internal Definitions
 * @version @PROJECT_VERSION@
 */

#ifndef NPIE_INTERNAL_H
#define NPIE_INTERNAL_H

#include "npie.h"
#include <pthread.h>
#include <stdbool.h>

#include <stddef.h>

#ifdef __cplusplus
extern "C" {
#endif

/* Internal configuration */
#define NPIE_MAX_MODELS 32
#define NPIE_MAX_ACCELERATORS 16
#define NPIE_MAX_BACKENDS 8
/* Accelerator descriptors and capabilities (internal) */
typedef struct {
    char name[64];
    bool supports_fp32;
    bool supports_fp16;
    bool supports_int8;
    uint32_t max_batch_size;
    size_t memory_size;
} npie_accelerator_caps_t;

typedef struct {
    npie_accelerator_t type;
    int device_id;
    char name[64];
} npie_accelerator_desc_t;

#define NPIE_DEFAULT_THREAD_COUNT 4
/* Forward declarations */
struct npie_model;
struct npie_context;

/* Internal context structure (must match implementation) */
struct npie_context {
    npie_options_t options;
    npie_log_callback_t log_callback;
    void* log_user_data;
    pthread_mutex_t mutex;
    bool initialized;
    uint32_t model_count;
    npie_model_t* models;
    /* Hardware detection cache */
    bool accelerators_detected;
    npie_accelerator_t available_accelerators[16];
    uint32_t accelerator_count;
};

/* Internal model structure (must match implementation) */
struct npie_model {
    char name[256];
    char path[512];
    npie_backend_t backend;
    npie_accelerator_t accelerator;
    void* backend_handle;
    npie_context_t context;

    /* Model metadata */
    uint32_t input_count;
    uint32_t output_count;
    npie_tensor_t* inputs;
    npie_tensor_t* outputs;

    /* Model data */
    void* model_data;
    size_t model_size;

    bool loaded;
    pthread_mutex_t mutex;
};


/* Backend interface */
/* Backend function prototypes (used across C files) */
#ifdef NEURAOS_ENABLE_LITERT
npie_status_t npie_backend_litert_load(npie_model_t model);
npie_status_t npie_backend_litert_unload(npie_model_t model);
npie_status_t npie_backend_litert_inference(npie_model_t model,
                                           const npie_tensor_t* inputs,
                                           uint32_t num_inputs,
                                           npie_tensor_t* outputs,
                                           uint32_t num_outputs);
#endif

#ifdef NEURAOS_ENABLE_ONNXRUNTIME
npie_status_t npie_backend_onnx_load(npie_model_t model);
npie_status_t npie_backend_onnx_unload(npie_model_t model);
npie_status_t npie_backend_onnx_inference(npie_model_t model,
                                         const npie_tensor_t* inputs,
                                         uint32_t num_inputs,
                                         npie_tensor_t* outputs,
                                         uint32_t num_outputs);
#endif

#ifdef NEURAOS_ENABLE_EMLEARN
npie_status_t npie_backend_emlearn_load(npie_model_t model);
npie_status_t npie_backend_emlearn_unload(npie_model_t model);
npie_status_t npie_backend_emlearn_inference(npie_model_t model,
                                           const npie_tensor_t* inputs,
                                           uint32_t num_inputs,
                                           npie_tensor_t* outputs,
                                           uint32_t num_outputs);
#endif

typedef struct npie_backend_ops {
    const char* name;
    npie_status_t (*init)(void);
    npie_status_t (*cleanup)(void);
    npie_status_t (*load_model)(const char* path, void** handle);
    npie_status_t (*unload_model)(void* handle);
    npie_status_t (*run_inference)(void* handle, npie_tensor_t* inputs,
                                   int num_inputs, npie_tensor_t* outputs,
                                   int num_outputs);
    npie_status_t (*get_model_info)(void* handle, npie_model_info_t* info);
} npie_backend_ops_t;

/* Backend registration */
npie_status_t npie_register_backend(const npie_backend_ops_t* ops);

/* Backend implementations */
#ifdef NEURAOS_ENABLE_LITERT
extern const npie_backend_ops_t npie_litert_backend;
#endif

#ifdef NEURAOS_ENABLE_ONNXRUNTIME
extern const npie_backend_ops_t npie_onnx_backend;
#endif

#ifdef NEURAOS_ENABLE_EMLEARN
extern const npie_backend_ops_t npie_emlearn_backend;
#endif

#ifdef NEURAOS_ENABLE_WASMEDGE
extern const npie_backend_ops_t npie_wasm_backend;
#endif

/* Logging macros */
#define NPIE_LOG_ERROR(fmt, ...) \
    fprintf(stderr, "[NPIE ERROR] " fmt "\n", ##__VA_ARGS__)

#define NPIE_LOG_WARN(fmt, ...) \
    fprintf(stderr, "[NPIE WARN] " fmt "\n", ##__VA_ARGS__)

#define NPIE_LOG_INFO(fmt, ...) \
    fprintf(stdout, "[NPIE INFO] " fmt "\n", ##__VA_ARGS__)

#ifdef DEBUG
#define NPIE_LOG_DEBUG(fmt, ...) \
    fprintf(stdout, "[NPIE DEBUG] " fmt "\n", ##__VA_ARGS__)
#else
#define NPIE_LOG_DEBUG(fmt, ...)
#endif

#ifdef __cplusplus
}
#endif

#endif /* NPIE_INTERNAL_H */

